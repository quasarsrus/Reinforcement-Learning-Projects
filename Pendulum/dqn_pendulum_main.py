# -*- coding: utf-8 -*-
"""DQN_Pendulum_main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C8TbOZWxXAgucLaKbmJ4SYSWNzIIc_wJ
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/MyDrive/Colab Notebooks"
!pip install import-ipynb
import import_ipynb

from DQN_General import Agent
import numpy as np
from Pendulum_Environment import Pendulum

if __name__ == '__main__':
    env = Pendulum()
    n_games = 200
    agent = Agent(gamma = 0.99, epsilon = 1.0, alpha = 0.0001, input_dimens = 2,
                  n_actions = 21, mem_size = 1000000, batch_size = 64, epsilon_end = 0.01)

    scores = []
    episode_history = []

    for i in range(n_games):
        done = False
        score = 0
        obs = env.reset()
        j = 0
        while not done:
            action = agent.action_choice(obs)
            obs_new, reward, done, info = env.motion(action)
            score += reward
            agent.remember(obs, action, reward, obs_new, done)
            obs = obs_new
            agent.learn(j)
            j += 1
            if j == 200:
              break


        episode_history.append(agent.epsilon)
        scores.append(score)

        avgscore = np.mean(scores[max(0, i-100):(i+1)])
        print('epsiode', i, 'score %.2f' %score, 'averages %.2f' %avgscore)

        if i%10 == 0 and i>0:
            agent.savemodel()

for i in range(400):
        done = False
        score = 0
        obs = env.reset()
        j = 0
        while not done:
            action = agent.action_choice(obs)
            obs_new, reward, done, info = env.motion(action)
            score += reward
            agent.remember(obs, action, reward, obs_new, done)
            obs = obs_new
            agent.learn(j)
            j += 1
            if j == 200:
              break


        episode_history.append(agent.epsilon)
        scores.append(score)

        avgscore = np.mean(scores[max(0, i-100):(i+1)])
        print('epsiode', i, 'score %.2f' %score, 'averages %.2f' %avgscore)

        if i%10 == 0 and i>0:
            agent.savemodel()

import matplotlib.pyplot as plt
plt.plot(scores)

"""## **Policy Test**"""

done = False
score1 = 0
obs = env.reset()
angle = []
j=0
while not done:
      action = agent.action_choice(obs)
      #action = agent.t.forward_propagation(np.transpose(np.atleast_2d(obs)))
      #print(obs)
      #action = np.argmax(actions)
      angle.append(obs)
      obs_new, reward, done, info = env.motion(action)
      score1 += reward
      agent.remember(obs, action, reward, obs_new, done)
      obs = obs_new
      #agent.loadmodel()
      done = False
      j+=1
      if j == 1000:
        break

plt.plot(angle)

plt.plot(np.cos(angle))

